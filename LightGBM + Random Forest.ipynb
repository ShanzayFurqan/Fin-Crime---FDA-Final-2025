{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a45054-6cd3-4983-b01d-c3931a43a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73854358-8258-47a1-8827-53c770e369ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n",
      "=== Stacking Model (LightGBM + Random Forest) Performance ===\n",
      "Accuracy:  0.991\n",
      "Precision: 0.260\n",
      "Recall:    0.755\n",
      "F1 Score:  0.387\n",
      "ROC AUC:   0.922\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# STEP 2: Load and Prepare Data\n",
    "users = pd.read_csv(r\"C:\\Users\\ND.COM\\Downloads\\users.csv\")           \n",
    "transactions = pd.read_csv(r\"C:\\Users\\ND.COM\\Downloads\\transactions.csv\")  \n",
    "fraudsters = pd.read_csv(r\"C:\\Users\\ND.COM\\Downloads\\fraudsters.csv\")  \n",
    "print(\"Data Loaded\")\n",
    "\n",
    "fraud_ids = set(fraudsters['USER_ID'])\n",
    "\n",
    "txn_grp = transactions.groupby('USER_ID')\n",
    "user_features = txn_grp.agg(\n",
    "    trans_count=('ID', 'count'),\n",
    "    total_amount=('AMOUNT_GBP', 'sum'),\n",
    "    avg_amount=('AMOUNT_GBP', 'mean'),\n",
    "    failed_count=('STATE', lambda x: (x == 'FAILED').sum()),\n",
    "    currency_count=('CURRENCY', pd.Series.nunique)\n",
    ").reset_index()\n",
    "user_features['fail_rate'] = user_features['failed_count'] / user_features['trans_count']\n",
    "\n",
    "type_dummies = pd.get_dummies(transactions['TYPE'])\n",
    "type_counts = transactions[['USER_ID']].join(type_dummies).groupby('USER_ID').sum().reset_index()\n",
    "\n",
    "features = pd.merge(user_features, type_counts, on='USER_ID', how='left')\n",
    "features = pd.merge(features, users, left_on='USER_ID', right_on='ID', how='left')\n",
    "today = datetime(2025, 5, 15)\n",
    "features['CREATED_DATE'] = pd.to_datetime(features['CREATED_DATE'], errors='coerce')\n",
    "features['BIRTH_DATE'] = pd.to_datetime(features['BIRTH_DATE'], errors='coerce')\n",
    "features['account_age_days'] = (today - features['CREATED_DATE']).dt.days\n",
    "features['user_age'] = ((today - features['BIRTH_DATE']).dt.days / 365).astype(int)\n",
    "features.drop(['CREATED_DATE', 'BIRTH_DATE', 'ID'], axis=1, inplace=True)\n",
    "features = pd.get_dummies(features, columns=['COUNTRY'], prefix='Country')\n",
    "features['is_fraud'] = features['USER_ID'].isin(fraud_ids).astype(int)\n",
    "features.drop('USER_ID', axis=1, inplace=True)\n",
    "\n",
    "# STEP 3: Train-Test Split and Scaling\n",
    "X = features.drop('is_fraud', axis=1)\n",
    "y = features['is_fraud']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# STEP 4: Handling Class Imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# STEP 5: Define Base Models with Adjusted Class Weights\n",
    "lgb = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=7, class_weight={0:1, 1:5}, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=7, class_weight={0:1, 1:5}, random_state=42, n_jobs=-1)\n",
    "\n",
    "# STEP 6: Define Meta Model\n",
    "meta_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# STEP 7: Create and Train Stacking Classifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('lgb', lgb), ('rf', rf)],\n",
    "    final_estimator=meta_model,\n",
    "    passthrough=False,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# STEP 8: Evaluation with Adjusted Threshold\n",
    "y_proba = stacking_model.predict_proba(X_test_scaled)[:, 1]\n",
    "threshold = 0.3  # Adjust as needed\n",
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "print(\"=== Stacking Model (LightGBM + Random Forest) Performance ===\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, zero_division=0):.3f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred):.3f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d382b7c-fe02-4d27-ae81-7b8e85eff7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
